{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 保存为checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "# 每个批次64张照片\n",
    "batch_size = 64\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='x_input')\n",
    "y = tf.placeholder(tf.float32, [None, 10], name='y_input')\n",
    "\n",
    "# 神经网络结构\n",
    "W = tf.Variable(tf.truncated_normal([784,10],stddev=0.1))\n",
    "b = tf.Variable(tf.zeros([10])+0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b, name='output')\n",
    "\n",
    "# 交叉熵代价函数\n",
    "loss = tf.losses.softmax_cross_entropy(y, prediction)\n",
    "# 使用Adam优化器\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss, name='train')\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#求准确率\n",
    "correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 test accuracy: 0.9044\n",
      "iter: 2 test accuracy: 0.9154\n",
      "iter: 3 test accuracy: 0.9198\n",
      "iter: 4 test accuracy: 0.9238\n",
      "iter: 5 test accuracy: 0.9248\n",
      "iter: 6 test accuracy: 0.9263\n",
      "iter: 7 test accuracy: 0.9286\n",
      "iter: 8 test accuracy: 0.9273\n",
      "iter: 9 test accuracy: 0.9278\n",
      "iter: 10 test accuracy: 0.93\n",
      "iter: 11 test accuracy: 0.9281\n"
     ]
    }
   ],
   "source": [
    "# 定义一个Saver用于保存\n",
    "Saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 初始化变化\n",
    "    sess.run(init)\n",
    "    for epoch in range(11):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x:batch_xs, y:batch_ys})\n",
    "        #每个周期计算准确率\n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "        print('iter: ' + str(epoch + 1) + \" test accuracy: \" + str(acc))\n",
    "    #保存训练模型\n",
    "    Saver.save(sess, 'test_ckpt_model/my_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.从checkpoint恢复之同时存在.ckpt和.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from test_ckpt_model/my_model.ckpt\n",
      "0.9281\n",
      "iter: 1 test acc: 0.9303\n",
      "iter: 2 test acc: 0.9305\n",
      "iter: 3 test acc: 0.9301\n",
      "iter: 4 test acc: 0.9306\n",
      "iter: 5 test acc: 0.9316\n",
      "iter: 6 test acc: 0.9318\n",
      "iter: 7 test acc: 0.9326\n",
      "iter: 8 test acc: 0.9309\n",
      "iter: 9 test acc: 0.9319\n",
      "iter: 10 test acc: 0.9322\n",
      "iter: 11 test acc: 0.9317\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "# 定义批次大小\n",
    "batch_size = 64\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 载入模型结构\n",
    "    saver = tf.train.import_meta_graph('test_ckpt_model/my_model.ckpt.meta')\n",
    "    # 载入模型参数\n",
    "    saver.restore(sess, 'test_ckpt_model/my_model.ckpt')\n",
    "    \n",
    "    #根据tensor的名字获取对应的tensor\n",
    "    # 之前保存模型的时候模型输出保存为output，\":0\"是保存模型参数时自动加上的，所以这里也要写上\n",
    "    output = sess.graph.get_tensor_by_name('output:0')\n",
    "    # 根据tensor的名字获取到对应的tensor\n",
    "    # 之前保存模型的时候准确率计算保存为accuracy，\":0\"是保存模型参数时自动加上的，所以这里也要写上\n",
    "    accuracy = sess.graph.get_tensor_by_name('accuracy:0')\n",
    "    # 之前保存模型的时候模型训练保存为train，注意这里的train是operation不是tensor\n",
    "    train_step = sess.graph.get_operation_by_name('train')\n",
    "    \n",
    "    # 把测试集喂到网络中计算准确率\n",
    "    # x-input是模型数据的输入，\":0\"是保存模型参数时自动加上的，所以这里也要写上\n",
    "    # y-input是模型标签的输入，\":0\"是保存模型参数时自动加上的，所以这里也要写上\n",
    "    print(sess.run(accuracy, feed_dict={'x_input_1:0':mnist.test.images, 'y_input_1:0':mnist.test.labels}))\n",
    "    \n",
    "    # 在原来模型的基础上再训练11个周期\n",
    "    for epoch in range(11):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys =  mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={'x_input_1:0':batch_xs,'y_input_1:0':batch_ys})\n",
    "        #准确率\n",
    "        acc = sess.run(accuracy, feed_dict={'x_input_1:0':mnist.test.images, 'y_input_1:0':mnist.test.labels})\n",
    "        print('iter: ' + str(epoch + 1) + ' test acc: ' + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.从checkpoit数据恢复方法之二 无.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "0.098\n",
      "INFO:tensorflow:Restoring parameters from test_ckpt_model/my_model.ckpt\n",
      "0.9281\n",
      "Iter 0,Testing Accuracy 0.9301\n",
      "Iter 1,Testing Accuracy 0.9289\n",
      "Iter 2,Testing Accuracy 0.931\n",
      "Iter 3,Testing Accuracy 0.9314\n",
      "Iter 4,Testing Accuracy 0.9313\n",
      "Iter 5,Testing Accuracy 0.9321\n",
      "Iter 6,Testing Accuracy 0.9319\n",
      "Iter 7,Testing Accuracy 0.933\n",
      "Iter 8,Testing Accuracy 0.9315\n",
      "Iter 9,Testing Accuracy 0.9327\n",
      "Iter 10,Testing Accuracy 0.9333\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "# 定义批次大小\n",
    "batch_size = 64\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "# 创建一个简单的神经网络，输入层784个神经元，输出层10个神经元\n",
    "# 这里的模型参数需要跟之前训练好的模型参数一样\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "# 计算准确率\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "# 定义saver用来载入模型\n",
    "# max_to_keep=5,在指定路径下最多保留5个模型，超过5个模型就会删除老的模型\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "# 交叉熵代价函数\n",
    "loss = tf.losses.softmax_cross_entropy(y, prediction)\n",
    "# 使用Adam优化器\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "# 定义会话\n",
    "with tf.Session() as sess:\n",
    "    # 变量初始化\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 计算测试集准确率\n",
    "    print(sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels}))\n",
    "    \n",
    "    # 载入训练好的参数\n",
    "    saver.restore(sess,'test_ckpt_model/my_model.ckpt')\n",
    "    # 在此计算准确率\n",
    "    print(sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels}))\n",
    "    \n",
    "    # 在原来模型的基础上再训练11个周期\n",
    "    for epoch in range(11):\n",
    "        for batch in range(n_batch):\n",
    "            # 获取一个批次的数据和标签\n",
    "            batch_xs,batch_ys =  mnist.train.next_batch(batch_size)\n",
    "            # 训练模型\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        # 计算测试集准确率\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        # 打印信息\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
    "        # 保存模型，global_step可以用来表示模型的训练次数或者训练周期数\n",
    "        saver.save(sess, 'test_ckpt_model/my_model.ckpt', global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
